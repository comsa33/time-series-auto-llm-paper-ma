제 Ⅴ 장 결론 및 향후 연구
제 1 절 연구 결과 요약
본 연구에서는 생성형 AI 기반의 시계열 예측 자동화 프레임워크를 제안하고, 이를 서울시 대기질(PM2.5) 데이터 사례에 적용하여 실증하였다. 다양한 시계열 예측 모델(지수평활법, ARIMA, Prophet, LSTM, Transformer)을 한데 모아 비교하고, 대규모 언어 모델(Gemma3:27B)의 지식을 활용하여 각 모델의 하이퍼파라미터를 자동으로 조율함으로써 성능 향상을 이끌어낸 점이 본 연구의 주요 기여이다. 또한 LLM을 통해 예측 결과에 대한 자연어 분석 보고서까지 자동 생성하여, 데이터 사이언스 작업의 엔드투엔드 자동화 가능성을 보여주었다.
연구 결과를 요약하면 다음과 같다. 첫째, 기본 모델 비교에서는 Transformer 모델이 RMSE 3.66, R² 0.89, MAPE 15.21%로 가장 우수한 성능을 보였으나, LLM 기반 튜닝을 거친 LSTM 모델이 RMSE 2.77, R² 0.94, MAPE 12.31%로 최고의 예측 성능을 달성하였다. 이는 기본 LSTM 모델 대비 RMSE 39.49%, MAPE 36.25% 등 평균 40% 내외의 성능 향상을 의미한다. 둘째, 대규모 언어 모델을 활용한 하이퍼파라미터 자동 튜닝이 효과적임이 확인되었다. LLM이 제안한 LSTM 레이어 수와 유닛 증가([64, 32]), 입력 시퀀스 길이 확장(24→48), Dropout 추가(0.2) 등의 개선 방안이 실제 성능 향상으로 이어졌다. 이는 LLM이 내부 지식을 활용해 모델러의 역할을 일부 대행할 수 있음을 의미한다. 셋째, 완전 자동화된 분석 보고가 가능함을 보였다. LLM은 모델 성능을 평가하고 최적 모델을 추천하며, 각 모델의 장단점을 기술하고 개선 제안을 제시하는 등 사람 전문가 수준의 보고서를 생성해 주었다. 이를 통해 미래에는 보고서 작성과 같은 부가 작업에도 소요 시간을 크게 줄일 수 있을 것으로 기대된다.
한편, 흥미로운 결과로 통계 기반 모델들이 LLM 튜닝 후 극적인 성능 향상을 보였다는 점이 있다. 지수평활법은 RMSE가 77.96% 감소했고, Prophet은 R²이 -6.06에서 0.33으로 개선되었다. 그러나 Transformer 모델의 경우, LLM이 제안한 복잡도 증가가 오히려 성능 저하를 초래했다. 이는 LLM의 모든 제안이 항상 성능 향상으로 이어지는 것은 아니며, 실험적 검증의 중요성을 보여준다.
