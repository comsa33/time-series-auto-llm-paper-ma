4.3 LLM 기반 하이퍼파라미터 튜닝 결과
앞서 4.2절에서 비교한 모델 중 LSTM은 성능이 두 번째로 우수했지만, 최고 성능을 보인 Transformer와는 다소 차이가 있었다. 이에 3.4절에서 소개한 LLM 기반 하이퍼파라미터 튜닝 접근법을 LSTM 모델에 적용하여, 성능을 더욱 개선할 수 있는지 실험하였다. 이 과정에서 LSTM 모델에 대한 구조와 학습 관련 하이퍼파라미터에 대해 Gemma3:27B 모델에 조언을 구했으며, 이를 바탕으로 모델을 재구성하고 훈련하였다.

LLM은 원래 LSTM 모델의 성능과 구조를 분석한 후, 다음과 같은 하이퍼파라미터 조정 방안을 제시하였다:

```python
# 기존 LSTM 파라미터
{
  "n_steps": 24,
  "lstm_units": [32],
  "epochs": 30
}

# LLM 추천 LSTM 파라미터
{
  "n_steps": 48,
  "lstm_units": [64, 32],
  "epochs": 100,
  "batch_size": 32,
  "dropout": 0.2,
  "learning_rate": 0.001
}
```

LLM이 추천한 주요 변경사항은 다음과 같다:
- **레이어 수 및 유닛 증가**: 기존 단일 레이어(32 유닛)에서 2개 레이어(64-32 유닛)로 모델 복잡도 증가
- **입력 시퀀스 길이 확장**: n_steps를 24에서 48로 늘려 더 긴 과거 데이터 활용
- **에포크 증가**: 30에서 100으로 늘려 충분한 학습 보장
- **Dropout 추가**: 0.2의 dropout 적용으로 과적합 방지
- **학습률 명시**: 0.001의 적절한 학습률 설정

LLM이 이러한 조정을 추천한 주요 근거는 다음과 같다:
1. 데이터의 복잡성을 고려할 때 더 깊은 네트워크가 패턴을 잘 포착할 것으로 판단
2. 시계열 데이터의 자기상관 특성상 더 긴 입력 시퀀스가 예측에 도움이 될 것으로 예상
3. 과적합 방지와 안정적인 학습을 위한 dropout 및 적절한 학습률의 중요성 강조

이러한 추천 사항을 반영하여 LSTM 모델을 재구성하고 훈련한 결과, 표 4.2와 같이 성능이 상당히 개선되었다.

표 4.2: LLM 튜닝 전후 LSTM 모델 성능 비교
| 모델 | MSE | RMSE | MAE | R² | MAPE (%) |
|------|-----|------|-----|-----|----------|
| 기본 LSTM | 22.09 | 4.70 | 3.48 | 0.81 | 22.09 |
| LLM 튜닝 LSTM | 7.63 | 2.76 | 2.11 | 0.94 | 12.49 |
| 성능 향상 | 65.46% ↑ | 41.23% ↑ | 39.33% ↑ | 14.89% ↑ | 43.47% ↑ |

![AI 튜닝 LSTM 예측 비교](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/ai_tuned_lstm_forecast_comparision_plot_pm25.png)

그림 4.4: 기본 LSTM과 LLM 튜닝 LSTM의 예측 결과 비교

표 4.2와 그림 4.4에서 볼 수 있듯이, LLM 튜닝을 거친 LSTM 모델은 기존 LSTM 모델 대비 모든 평가 지표에서 크게 개선되었다. MSE는 65.46%, RMSE는 41.23%, MAE는 39.33%, MAPE는 43.47% 향상되었으며, 설명력을 나타내는 R²도 14.89% 증가하였다. 특히 주목할 만한 점은 튜닝된 LSTM의 RMSE가 2.76, MAPE가 12.49%로, 4.2절에서 최고 성능을 보였던 Transformer 모델(RMSE 3.24, MAPE 14.21%)보다도 더 뛰어난 예측 성능을 달성했다는 것이다.

이러한 결과는 LLM이 단순히 자연어 처리 외에도, 딥러닝 모델의 하이퍼파라미터 최적화와 같은 전문적인 영역에서도 실질적인 도움을 줄 수 있음을 보여준다. Gemma3:27B 모델은 시계열 분석이나 딥러닝에 대한 직접적인 미세 조정을 받지 않았음에도, 내재한 학습 지식을 바탕으로 모델 구조와 하이퍼파라미터에 대한 적절한 조언을 제시할 수 있었다. 이는 대규모 언어 모델이 프롬프트 엔지니어링만으로도 전문 도메인의 의사결정 과정을 지원할 수 있는 가능성을 입증한다.

4.4 시계열 특성 분석 및 데이터 인사이트

PM2.5 시계열 데이터에 대한 더 깊은 이해를 위해, 본 연구에서는 추가적인 시계열 특성 분석을 수행하였다. 이 분석은 예측 모델의 성능 차이와 성공 요인을 이해하는 데 중요한 맥락을 제공한다.

![시계열 분해](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/timeseries_decomposition_plot_pm25.png)

그림 4.5: PM2.5 시계열 분해 (추세, 계절성, 잔차 성분)

그림 4.5는 PM2.5 시계열 데이터를 추세(trend), 계절성(seasonality), 잔차(residual) 성분으로 분해한 결과이다. 분해 결과, 다음과 같은 특징을 확인할 수 있다:

1. **강한 일중 계절성**: 24시간 주기의 뚜렷한 일중 패턴이 존재하며, 주로 오전과 저녁 시간대에 높은 농도를 보이는 경향이 있다. 이는 사람들의 출퇴근 시간과 관련이 있을 수 있다.

2. **중기 추세 변동**: 전체 기간 동안 미세한 증가 및 감소 추세가 관찰되며, 일부 구간에서는 갑작스러운 변화가 있다.

3. **불규칙한 잔차**: 잔차 성분에는 여전히 상당한 변동성이 남아있으며, 이는 날씨와 같은 외부 요인의 영향일 수 있다.

이러한 복잡한 시계열 구조는 왜 단순한 통계 모델(Exponential Smoothing, ARIMA, Prophet)이 예측에 실패했고, 딥러닝 모델(LSTM, Transformer)이 우수한 성능을 보였는지 설명해준다. 딥러닝 모델은 비선형 패턴을 학습하고 장기 의존성을 포착하는 능력이 뛰어나기 때문에, 이러한 복잡한 시계열 데이터에 더 적합했던 것으로 판단된다.

![자기상관 및 편자기상관 함수](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/acf_pacf_plot_pm25.png)

그림 4.6: PM2.5 시계열의 자기상관(ACF) 및 편자기상관(PACF) 함수

그림 4.6은 PM2.5 시계열의 자기상관(ACF) 및 편자기상관(PACF) 함수를 보여준다. ACF 플롯에서 뚜렷한 24시간 주기성(lag 24, 48, 72 등에서의 피크)이 관찰되며, 이는 앞서 확인한 강한 일중 계절성을 다시 한번 확인해준다. PACF 플롯에서는 lag 1, 24에서 유의미한 상관관계가 관찰되며, 이는 ARIMA 모델에서 p=1, P=1, s=24와 같은 파라미터가 적절할 수 있음을 시사한다. 그러나 ARIMA 모델의 성능이 좋지 않았던 이유는, 이러한 선형적 자기상관 구조 외에도 비선형적인 패턴과 외부 변수의 영향이 크게 작용했기 때문으로 보인다.

![상관관계 히트맵](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/timeseries_corelation_heatmap_plot.png)

그림 4.7: 다양한 대기 오염 물질 간의 상관관계 히트맵

그림 4.7은 PM2.5와 다른 대기 오염 물질(PM10, SO2, NO2, O3, CO) 간의 상관관계를 히트맵으로 시각화한 것이다. 분석 결과, PM2.5는 PM10과 가장 강한 상관관계(0.91)를 보였으며, CO(0.74)와 NO2(0.68)와도 상당한 상관관계가 있었다. 이러한 결과는 대기 오염 물질들 사이의 상호 연관성을 보여주며, 미래에는 이러한 다변량 정보를 활용한 예측 모델이 더 정확한 결과를 제공할 가능성을 시사한다.

![그레인저 인과성 테스트](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/timeseries_granger_plot_pm10_to_pm25.png)

그림 4.8: PM10에서 PM2.5로의 그레인저 인과성 테스트 결과

그림 4.8은 PM10이 PM2.5의 변화를 얼마나 예측하는데 도움이 되는지를 보여주는 그레인저 인과성 테스트 결과이다. 테스트 결과, PM10은 PM2.5에 대해 통계적으로 유의미한 그레인저 인과성을 가지는 것으로 나타났다(p-value < 0.05). 이는 PM10의 과거 값이 PM2.5의 미래 값을 예측하는 데 유용한 정보를 제공할 수 있음을 의미하며, 향후 다변량 모델 개발 시 고려해야 할 중요한 인사이트이다.

이러한 시계열 특성 분석 결과는 왜 일부 모델이 더 성공적이었는지, 그리고 어떤 데이터 특징이 예측에 중요한 역할을 하는지에 대한 이해를 심화시켜준다. 특히, 강한 일중 주기성은 LLM이 LSTM 모델의 n_steps 파라미터를 24에서 48로 증가시키도록 제안한 이유를 설명해주며, 이러한 조정이 모델 성능 향상에 큰 기여를 했을 것으로 판단된다.

4.5 결과 분석 및 최적 모델 선정
앞 절의 성능 비교를 통해, 어떤 모델이 최적의 선택인지 명확해졌다. LSTM 모델이 본 데이터셋에서 가장 우수한 예측 정확도를 보였으므로, 최적 모델로 선정한다. LSTM을 최적 모델로 추천하는 근거는 다음과 같이 정리할 수 있다:
가장 낮은 예측 오차: LSTM의 RMSE, MAE, MAPE 값은 다른 어떤 모델보다도 현저히 낮았다. 이는 평균 오차 규모가 최소이며, 실제 관측치에 매우 근접한 예측을 내놓았음을 의미한다. 특히 MAPE 12.49%는 다른 모델들이 100% 이상인 것에 비해 월등히 작은 값으로, 예측 정확도 측면에서 LSTM이 압도적이다.

높은 설명력: LSTM의 결정계수 R² = 0.94로, 1에 가까운 높은 값을 보였다. R² 값이 높다는 것은 모델이 데이터의 패턴과 변동을 잘 설명하고 있다는 뜻이다. 0.94는 94%의 분산을 설명한다는 의미이므로, 나머지 오차 요인 6%만이 설명되지 않은 것이다. 다른 모델들의 R²이 음수 내지 거의 0인 것과 비교하면, LSTM의 모형 적합도가 뛰어남을 알 수 있다.

시계열 데이터 처리 능력: LSTM은 **순환신경망(RNN)**의 특수한 형태로서, 시간적 순서 정보와 장기 의존성을 학습하는 데 강점이 있다. PM2.5 농도와 같이 하루 주기의 계절성과 이전 시간의 영향이 혼재하는 데이터에서는, 과거 상태를 메모리셀에 저장하며 필요한 시점에 꺼내 쓰는 LSTM의 구조가 매우 적합하다. 실제로 LSTM은 이 데이터를 통해 일중 주기 패턴뿐만 아니라 이례적 피크와 급락 현상까지도 어느 정도 예측해낸 것으로 보인다. 이는 LSTM의 시계열 특화된 학습능력이 큰 역할을 했다고 할 수 있다.

以上의 이유들로, LSTM 모델을 본 연구의 대상 데이터에 대한 최적의 예측 모델로 결정하였다.
한편, Transformer 모델도 높은 순위의 후보였지만, LSTM보다 약간 열세인 성능으로 2순위에 머물렀다. Transformer는 이론적으로 장기 의존 학습에 유리하나, 실용적인 데이터량 측면에서 LSTM만큼 효과를 발휘하지 못한 것으로 판단된다. 만약 더 대규모의 데이터가 주어진다면 Transformer도 LSTM을 뛰어넘을 가능성이 있다.
ARIMA, Prophet, 지수평활법은 이번 실험에서는 좋은 성능을 내지 못했으나, 이것이 항상 열등하다는 뜻은 아니다. 이들 모델은 주로 선형 경향이나 명시적 계절 패턴이 뚜렷한 경우에 유용하다. 본 데이터는 단기간의 복잡한 변동이라 해당 조건에 부합하지 않았지만, 만약 장기간 추세를 예측하거나 외생 변수 없이도 주기성을 잘 반영할 수 있는 경우라면 ARIMA나 Prophet도 유효한 선택일 수 있다.
이번 결과를 토대로 모델의 장단점을 데이터 특성과 연결지어 정리하면 표 4.3과 같다. 각각의 모델이 가지는 일반적인 장점과 단점을 기술하고, 본 연구의 PM2.5 데이터 특성에 비추어 적합성 정도를 낮음/중간/높음으로 평가하였다.

표 4.3: 데이터 특성에 따른 각 모델의 장단점 및 적합성
| 모델 | 장점 | 단점 | 본 데이터에 대한 적합성 |
|------|------|------|------------------------|
| Exponential Smoothing | 구현이 간단하고 계산이 빠름 | 뚜렷한 추세나 계절성 패턴은 제대로 학습 못함 | 낮음 |
| ARIMA | 자기상관성을 명시적으로 모델링함 | 계절성은 별도로 모형화 필요, 데이터 정상성 가정 | 중간 |
| Prophet | 추세와 계절성을 자동으로 처리, 이상치에 강건함 | 복잡한 비주기 패턴은 포착 어려움 | 중간 |
| LSTM | 긴 시계열의 복잡한 패턴도 학습 가능 | 많은 데이터 필요, 학습 시간 김, 모형 해석 어려움 | 높음 |
| Transformer | 병렬처리로 효율적, 장거리 의존 학습에 효과적 | 매우 큰 데이터 요구, 구조 복잡해 튜닝 어려움 | 높음 |

표 4.3에서 볼 수 있듯, LSTM과 Transformer는 본 데이터에 대한 적합성이 ‘높음’으로 평가된다. 이는 이들 딥러닝 모델이 비선형적이고 복잡한 일중 변동 및 급격한 변화 등의 특성을 잘 흡수했기 때문이다. 반면 Exponential Smoothing은 단순한 모형이라 ‘낮음’으로 평가되며, ARIMA와 Prophet은 일정 부분 패턴을 반영하지만 한계로 인해 ‘중간’ 수준에 머물렀다.
결과적으로, LLM의 도움을 받아 튜닝된 LSTM 모델이 최고 성능을 냈고, 이는 생성형 AI를 활용한 모델 최적화 전략이 적절히 작동했음을 의미한다. 다음으로는, 이렇게 얻은 최종 LSTM 모델을 이용한 미래 예측값의 해석 및 신뢰도 평가에 대해 간략히 언급한다.
(참고: 향후 실시간 운영 시에는 최적 모델인 LSTM을 활용하여 PM2.5 농도의 미래 변화를 지속 예측하게 된다. 이때 예측값의 신뢰도를 판단하기 위해 과거 오차 수준과 데이터 안정성, 외부 요인 등을 고려해야 한다. 예측 결과 활용에 있어 이러한 부분도 중요하지만, 본 논문의 범위에서는 자세한 논의는 생략한다.)
