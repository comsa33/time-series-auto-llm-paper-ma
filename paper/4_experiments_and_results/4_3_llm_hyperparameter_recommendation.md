제 3 절 LLM 기반 하이퍼파라미터 튜닝 결과
앞서 제2절에서 각 모델의 기본 성능을 비교한 결과, 딥러닝 기반 모델(LSTM, Transformer)이 통계 기반 모델(지수평활법, ARIMA, Prophet)보다 월등히 우수한 성능을 보였다. 본 절에서는 3.4절에서 소개한 LLM 기반 하이퍼파라미터 튜닝 방법을 각 모델에 적용하여 성능 개선 효과를 분석한다.
(1) 모델별 LLM 하이퍼파라미터 튜닝 제안
LLM은 각 모델의 현재 성능과 구조를 분석하여 다음과 같은 하이퍼파라미터 조정 방안을 제시하였다.
지수평활법(Exponential Smoothing) 모델 LLM은 기존 가법적(additive) 추세와 계절성을 승법적(multiplicative) 모형으로 변경하고, 댐핑된 추세(damped_trend)를 활성화하는 방안을 제안하였다. 또한 평활 상수 alpha와 beta를 각각 0.3과 0.1로 설정하여 최근 데이터와 추세 변화에 더 민감하게 반응하도록 조정하였다. 이러한 변경은 데이터의 뚜렷한 계절성 패턴과 높은 변동성을 효과적으로 반영하기 위한 것으로, LLM은 이를 통해 RMSE를 10-20% 감소시킬 수 있을 것으로 예상하였다.
ARIMA 모델 ARIMA 모델에 대해 LLM은 자기상관성이 더 강하게 나타나는 점을 고려하여 AR 및 MA 차수를 각각 1에서 2로 증가시키는 변경을 제안하였다. 또한 최적의 모형을 찾기 위해 max_p와 max_q를 5로 늘리고, stepwise 방식을 비활성화하여 더 다양한 모형 조합을 탐색하도록 하였다. 이는 ACF와 PACF 그래프에서 확인된 더 넓은 범위의 유의미한 상관관계를 반영한 것이다. 조정된 파라미터는 order=[2,1,2], seasonal_order=[1,1,1,24], stepwise=False, n_jobs=-1 등으로 변경되었다.
Prophet 모델 Prophet 모델에 대해서는 changepoint_prior_scale을 0.01에서 0.1로 증가시켜 데이터의 변화 지점을 더 민감하게 감지하도록 하였다. 또한 daily_seasonality를 활성화하고, weekly_seasonality와 yearly_seasonality 강도를 각각 10으로 설정하여 다양한 주기의 계절성을 모델링하도록 제안하였다. 특히 seasonality_prior_scale을 10으로 설정하여 계절성 패턴을 더 강하게 반영하도록 하였다.
LSTM 모델 LSTM 모델에 대해서는 모델 구조와 학습 관련 파라미터를 모두 조정하는 포괄적인 변경을 제안하였다. 구체적으로는 LSTM 유닛 수를 단일 레이어 32개에서 [64, 32]의 두 층 구조로 변경하여 모델의 표현력을 향상시키고, 입력 시퀀스 길이(n_steps)를 24에서 48로 늘려 더 긴 시간 의존성을 학습하도록 하였다. 또한 학습 에폭 수를 30에서 100으로 증가시키고, 과적합 방지를 위한 dropout(0.2)과 batch_size(32), learning_rate(0.001) 등의 파라미터도 최적화하였다.
Transformer 모델 Transformer 모델에 대해서는 window_size를 24에서 48로 늘려 더 넓은 범위의 과거 정보를 활용하도록 하고, 임베딩 차원(embed_dim)을 32에서 64로, 어텐션 헤드 수(num_heads)를 2에서 4로 증가시켜 모델의 표현력을 강화하는 방안을 제안하였다. 또한 피드포워드 차원(ff_dim)을 64에서 128로, 레이어 수(num_layers)를 1에서 2로 늘리고, epochs를 30에서 50으로 증가시켜 모델이 데이터를 더 깊게 학습하도록 하였다. 과적합 방지를 위한 dropout(0.2)과 learning_rate(0.001) 설정도 함께 제안되었다.
(2) 튜닝 결과 및 성능 향상 분석
LLM이 제안한 하이퍼파라미터를 적용하여 각 모델을 재학습한 결과는 표 4와 같다.
<표 4> LLM 튜닝 전후 모델별 성능 비교
모델	지표	튜닝 전	튜닝 후	향상률(%)
지수평활법	MSE	3879.49	188.53	95.14% ↑
  RMSE	62.29	13.73	77.96% ↑
  MAE	52.65	10.54	79.98% ↑
  R²	-31.53	-0.58	98.16% ↑
  MAPE	492.73%	94.48%	80.83% ↑
ARIMA	MSE	184.06	119.22	35.23% ↑
  RMSE	13.57	10.92	19.52% ↑
  MAE	10.13	8.56	15.46% ↑
  R²	-0.54	0.0003	100.06% ↑
  MAPE	103.21%	67.40%	34.70% ↑
Prophet	MSE	841.61	80.11	90.48% ↑
  RMSE	29.01	8.95	69.15% ↑
  MAE	24.06	7.34	69.48% ↑
  R²	-6.06	0.33	105.42% ↑
  MAPE	112.67%	28.68%	74.55% ↑
LSTM	MSE	20.93	7.66	63.38% ↑
  RMSE	4.57	2.77	39.49% ↑
  MAE	3.54	2.22	37.17% ↑
  R²	0.82	0.94	13.49% ↑
  MAPE	19.31%	12.31%	36.25% ↑
Transformer	MSE	13.41	28.79	-114.74% ↓
  RMSE	3.66	5.37	-46.54% ↓
  MAE	2.90	4.28	-47.69% ↓
  R²	0.89	0.76	-14.53% ↓
  MAPE	15.21%	26.60%	-74.96% ↓
LLM 기반 하이퍼파라미터 튜닝 결과를 분석하면 다음과 같은 주요 패턴을 발견할 수 있다.
통계 기반 모델의 극적인 성능 향상 통계 기반 모델들은 LLM 튜닝을 통해 놀라운 성능 향상을 보였다. 특히 지수평활법은 MSE가 95.14% 감소하고 RMSE가 77.96% 감소하는 등 극적인 개선을 보였다. R² 값이 여전히 음수이기는 하지만 -31.53에서 -0.58로 대폭 개선되었다. Prophet 모델 역시 MSE 90.48%, RMSE 69.15% 감소 등의 큰 향상을 보였으며, R² 값이 -6.06에서 0.33으로 양수로 전환되는 성과를 보였다. ARIMA 모델도 R² 값이 -0.54에서 0.0003으로 개선되었다. 이는 LLM이 각 모델의 특성을 이해하고 데이터의 패턴에 맞는 적절한 파라미터를 제안한 결과로 볼 수 있다.
LSTM 모델의 우수한 성능 향상 LLM 튜닝 전에도 우수한 성능을 보였던 LSTM 모델은 튜닝 후 더욱 향상된 성능을 보였다. MSE는 63.38% 감소하였고, RMSE는 4.57에서 2.77로 39.49% 감소하였다. R² 값은 0.82에서 0.94로 향상되었으며, MAPE는 19.31%에서 12.31%로 36.25% 개선되었다. 특히 LLM이 제안한 두 층 구조([64, 32] 유닛)와 더 긴 입력 시퀀스(48), 그리고 dropout과 같은 정규화 기법의 도입이 LSTM 모델의 표현력을 높이고 과적합을 방지하는 데 효과적이었던 것으로 보인다.
Transformer 모델의 성능 저하 흥미롭게도, 튜닝 전 가장 우수한 성능을 보였던 Transformer 모델은 LLM이 제안한 파라미터 변경 후 오히려 성능이 저하되었다. MSE는 114.74% 증가하였고, RMSE는 3.66에서 5.37로 46.54% 증가하였다. R² 값은 0.89에서 0.76으로 감소하였으며, MAPE는 15.21%에서 26.60%로 74.96% 증가하였다. 이는 모델 복잡도 증가(window_size 확대, 임베딩 차원 증가, 레이어 수 증가 등)가 제한된 데이터셋에서 과적합을 초래했을 가능성을 시사한다. 이 결과는 LLM의 모든 제안이 항상 성능 향상으로 이어지지는 않으며, 실험적 검증의 중요성을 보여준다.
최종 성능 비교 LLM 튜닝 후, LSTM 모델이 모든 평가 지표에서 가장 우수한 성능을 보였다. RMSE 2.77, MAE 2.22, R² 0.94, MAPE 12.31%로, 튜닝 전 가장 우수했던 Transformer 모델(RMSE 3.66, MAE 2.90, R² 0.89, MAPE 15.21%)보다 더 나은 결과를 달성하였다. 특히 R² 0.94는 모델이 PM2.5 데이터의 변동성을 94% 설명할 수 있음을 의미하여, 실용적 관점에서도 매우 신뢰할 만한 수준의 예측 성능이라 할 수 있다.
(3) LLM 튜닝의 유효성 및 시사점
LLM 기반 하이퍼파라미터 튜닝 실험 결과는 다음과 같은 중요한 시사점을 제공한다.
첫째, 대규모 언어 모델은 도메인 지식과 추론 능력을 바탕으로 시계열 모델의 하이퍼파라미터를 효과적으로 제안할 수 있음을 확인하였다. 특히 통계 기반 모델의 경우, 성능이 크게 개선되어 딥러닝 모델과의 격차가 줄어들었다.
둘째, 모델의 특성과 데이터 패턴에 따라 LLM 제안의 효과는 다르게 나타난다. 특히 이미 최적화에 가까운 모델(Transformer)은 추가적인 복잡도 증가가 오히려 성능 저하를 초래할 수 있음을 확인하였다. 이는 LLM의 제안을 항상 그대로 수용하기보다는 실험적 검증을 통해 선택적으로 적용해야 함을 시사한다.
셋째, LLM 기반 튜닝은 직관적인 설명을 제공한다는 장점이 있다. 예를 들어, LSTM 모델에서 입력 시퀀스 길이를 24에서 48로 늘리도록 제안한 것은 시계열 데이터의 일중 주기성과 더 넓은 범위의 자기상관성을 고려한 것으로, 단순한 무작위 탐색보다 효율적이고 해석 가능한 튜닝 방식을 제공한다.
넷째, LLM 기반 하이퍼파라미터 튜닝은 기존 AutoML 접근법과 보완적으로 사용될 수 있다. LLM이 도메인 지식을 바탕으로 탐색 공간을 효과적으로 축소하고, 그 안에서 기존 베이지안 최적화 등의 방법으로 세부 튜닝을 수행하는 하이브리드 접근법이 더 효과적일 수 있다.
결론적으로, LLM 기반 하이퍼파라미터 튜닝은 LSTM 모델에서 가장 성공적이었으며, 최종적으로 RMSE 2.77, R² 0.94, MAPE 12.31%의 우수한 성능을 달성하였다. 이는 튜닝 전 기본 LSTM 모델 대비 39.49%의 RMSE 감소, 36.25%의 MAPE 감소를 의미하며, PM2.5 농도 예측을 위한 최적의 모델로 선정할 수 있는 근거가 된다.
