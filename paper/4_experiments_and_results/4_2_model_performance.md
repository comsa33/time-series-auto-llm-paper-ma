4.2 모델별 성능 비교
표 4.1은 실험에 사용된 다섯 가지 모델의 예측 성능 지표를 요약한 것이다. 이 결과는 본 연구에서 LLM 기반 튜닝을 거친 최종 모델들을 이용해 산출한 것으로, 초기 설정 대비 일부 향상된 성능을 반영한다. 표와 함께 각 모델의 특징적인 성능을 분석한다.
표 4.1: 다섯 가지 모델의 예측 성능 비교 (테스트 세트 기준)
모델
MSE
RMSE
MAE
R²
MAPE (%)
Exponential Smoothing
63082.29
251.16
216.26
-548.02
1619.78
ARIMA
179.79
13.41
9.97
-0.56
100.22
Prophet
1015.36
31.86
27.01
-7.84
223.82
LSTM
18.38
4.29
3.22
0.84
19.63
Transformer
29.96
5.47
4.21
0.74
26.33

위 표에서 굵게 강조한 LSTM 모델의 성능이 가장 우수함을 알 수 있다. LSTM은 RMSE 4.29로 다른 모델들에 비해 월등히 낮은 오차를 보였으며, **MAPE 약 19.63%**로 예측값의 평균 오차율도 가장 작다. 결정계수 R²도 0.84로 유의미하게 0에 가까운 값을 나타내며 (1에 가까울수록 좋음), 이는 데이터 변동의 84%를 설명한다는 의미다. 반면에 Exponential Smoothing과 Prophet 모델은 예측이 거의 실패한 수준으로, MAPE가 각각 1600%와 224%에 달하며 R²이 큰 음수를 기록했다. 이는 해당 모델들이 평균으로 예측하는 것보다도 못한 성능을 보였음을 뜻한다. ARIMA 모델의 경우 MAPE 약 100%로, 예측값이 평균적으로 실제값의 2배 정도 오차를 보이는 수준이며 R²도 -0.56로 0 이하이다.
Transformer 모델은 LSTM 다음으로 우수한 성능을 보였다. RMSE 5.47, MAPE 26.33%로, LSTM보다는 다소 열세이지만 그래도 두 자릿수 MAPE를 유지하며 R² = 0.74로 **변동의 74%**를 설명하였다. 이는 Transformer가 LSTM과 마찬가지로 데이터의 주요 패턴을 상당 부분 포착했음을 보여준다.
모델별 성능 수치를 조금 더 자세히 비교하면 다음과 같은 특징을 정리할 수 있다:
Exponential Smoothing & Prophet: 두 모델 모두 **오차율(MAPE)**이 매우 높고 R²이 큰 음수이다. 이는 이 데이터셋에는 두 방법이 전혀 맞지 않다는 걸 의미한다. 특히 Exponential Smoothing의 R² = -548.02는 성능이 극도로 나쁨을 나타낸다. 이는 아마도 데이터의 변동성이 크고 계절성 패턴이 뚜렷해 단순 지수평활로는 감당하지 못했기 때문으로 보인다. Prophet 역시 기본적으로는 추세+계절 구조를 모델링하지만, 한 달의 짧은 데이터로는 오히려 잘못된 추세를 학습하여 과도한 예측 오차를 낸 것으로 판단된다.


ARIMA: ARIMA의 경우 R²는 -0.56으로 약간 음수인데, 이는 예측 성능이 단순 평균 모델보다도 떨어진다는 의미다. MAPE 100% 수준으로, 예측값과 실제값 사이에 상당한 비율 차이가 있음을 알 수 있다. ARIMA 모델이 부진한 원인은 짧은 데이터 기간과 고변동성 데이터에 기인한다. ARIMA는 충분한 데이터가 있고 자기상관이 명확한 경우 효과적이지만, 본 데이터의 경우 하루 주기의 계절성을 제대로 반영하지 못했고, 변동 폭이 큰 부분에서 오차가 누적된 것으로 보인다.


LSTM: 모든 지표에서 최고의 성능을 보였다. MSE, RMSE, MAE가 모두 가장 낮아 평균적인 예측 오차 규모가 작다. MAPE 19.63%는 예측값이 실제값과 거의 유사한 수준임을 뜻하며, R² 0.84는 모형이 매우 높은 설명력을 가짐을 나타낸다. 이는 LSTM이 일중 주기성 등 복잡한 패턴을 성공적으로 학습했음을 시사한다. 특히 R²이 양수 0.84로 유의미하게 높은 것은, 다른 저성능 모델들의 음수 R²와 대비되는 중요한 결과다.


Transformer: LSTM보다는 약간 성능이 떨어지지만 여전히 우수한 성능 그룹에 속한다. RMSE 5.47은 LSTM 대비 약 1.2㎍/m³ 정도 높은 수준이고, MAPE 26.33%도 LSTM보다 6.7%p 높다. R² 0.74로 LSTM보다 0.10 낮지만, 여전히 높은 설명력을 가진다. Transformer의 약간 낮은 성능은 데이터량 부족에 따른 학습 한계로 추정된다. Transformer는 LSTM보다 매개변수가 많고 복잡하여, 한 달치 데이터만으로는 최적화가 어려웠을 수 있다. 그럼에도 불구하고 LSTM 다음으로 좋은 결과를 보였다는 것은 Transformer의 잠재적 성능이 높음을 보여준다.


위의 결과를 종합하면, **딥러닝 기반 모델(LSTM, Transformer)**이 **통계적 모델(지수평활법, ARIMA, Prophet)**보다 월등히 뛰어난 예측 성능을 발휘했다. 특히 LSTM은 오차율 20% 미만으로, 실제 활용에도 무리가 없을 정도의 정확도를 달성하였다. 반면 지수평활법이나 Prophet은 시계열 decomposed 구조를 가정하고 있음에도 불구하고, 너무 짧고 변동이 심한 데이터 특성에 적응하지 못해 사실상 예측에 실패하였다. ARIMA는 어느 정도 기본적인 패턴은 맞추었으나, 정확도 면에서는 만족스럽지 않은 수준이다.
