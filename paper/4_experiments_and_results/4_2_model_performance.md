4.2 모델별 성능 비교
표 4.1은 실험에 사용된 다섯 가지 모델의 예측 성능 지표를 요약한 것이다(지수평활법[2], ARIMA[1], Prophet[3], LSTM[4], Transformer[5]). 이 결과는 본 연구에서 LLM 기반 튜닝을 거친 최종 모델들을 이용해 산출한 것으로, 초기 설정 대비 일부 향상된 성능을 반영한다. 표와 함께 각 모델의 특징적인 성능을 분석한다.

표 4.1: 다섯 가지 모델의 예측 성능 비교 (테스트 세트 기준)
| 모델 | MSE | RMSE | MAE | R² | MAPE (%) |
|------|-----|------|-----|-----|----------|
| Exponential Smoothing | 3879.49 | 62.29 | 52.65 | -31.53 | 432.92 |
| ARIMA | 184.06 | 13.57 | 10.13 | -0.54 | 103.21 |
| Prophet | 841.61 | 29.01 | 24.06 | -6.06 | 209.44 |
| LSTM | 18.38 | 4.29 | 3.22 | 0.84 | 19.63 |
| Transformer | 10.50 | 3.24 | 2.24 | 0.91 | 14.21 |

![모델별 성능 비교 시각화](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/model_performance_comparison_plots_pm25.png)

그림 4.1: 다섯 가지 모델의 예측 성능 비교 시각화

위 표와 그림 4.1에서 볼 수 있듯이, **Transformer 모델의 성능이 가장 우수함**을 알 수 있다. Transformer는 RMSE 3.24로 다른 모델들에 비해 월등히 낮은 오차를 보였으며, **MAPE 약 14.21%**로 예측값의 평균 오차율도 가장 작다. 결정계수 R²도 0.91로 매우 높은 값을 나타내며, 이는 데이터 변동의 91%를 설명한다는 의미다. 

LSTM 모델도 RMSE 4.29, MAPE 19.63%, R² 0.84로 우수한 성능을 보여주었다. 반면에 Exponential Smoothing과 Prophet 모델은 예측이 거의 실패한 수준으로, MAPE가 각각 432.92%와 209.44%에 달하며 R²이 큰 음수를 기록했다. 이는 해당 모델들이 평균으로 예측하는 것보다도 못한 성능을 보였음을 뜻한다. ARIMA 모델의 경우 MAPE 약 103.21%로, 예측값이 평균적으로 실제값의 2배 정도 오차를 보이는 수준이며 R²도 -0.54로 0 이하이다.

![모델별 예측 결과 비교](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/model_forecast_comparision_plot_pm25.png)

그림 4.2: 각 모델의 예측 결과와 실제 PM2.5 농도 비교

그림 4.2는 각 모델의 예측 결과를 실제 PM2.5 농도와 비교한 것이다. 딥러닝 기반 모델(LSTM, Transformer)이 실제 데이터의 패턴을 잘 따라가고 있는 반면, 통계적 모델들은 큰 오차를 보이고 있음을 시각적으로 확인할 수 있다.

모델별 성능 수치를 조금 더 자세히 비교하면 다음과 같은 특징을 정리할 수 있다:

Exponential Smoothing & Prophet: 두 모델 모두 **오차율(MAPE)**이 매우 높고 R²이 큰 음수이다. 이는 이 데이터셋에는 두 방법이 전혀 맞지 않다는 걸 의미한다. 특히 Exponential Smoothing의 R² = -31.53은 성능이 극도로 나쁨을 나타낸다. 이는 아마도 데이터의 변동성이 크고 계절성 패턴이 뚜렷해 단순 지수평활로는 감당하지 못했기 때문으로 보인다. Prophet 역시 기본적으로는 추세+계절 구조를 모델링하지만, 한 달의 짧은 데이터로는 오히려 잘못된 추세를 학습하여 과도한 예측 오차를 낸 것으로 판단된다.

ARIMA: ARIMA의 경우 R²는 -0.54로 약간 음수인데, 이는 예측 성능이 단순 평균 모델보다도 떨어진다는 의미다. MAPE 103.21% 수준으로, 예측값과 실제값 사이에 상당한 비율 차이가 있음을 알 수 있다. ARIMA 모델이 부진한 원인은 짧은 데이터 기간과 고변동성 데이터에 기인한다. ARIMA는 충분한 데이터가 있고 자기상관이 명확한 경우 효과적이지만, 본 데이터의 경우 하루 주기의 계절성을 제대로 반영하지 못했고, 변동 폭이 큰 부분에서 오차가 누적된 것으로 보인다.

LSTM: 두 번째로 우수한 성능을 보였다. MSE, RMSE, MAE가 Transformer 다음으로 낮았으며, MAPE 19.63%는 예측값이 실제값과 거의 유사한 수준임을 뜻한다. R² 0.84는 모형이 매우 높은 설명력을 가짐을 나타낸다. 이는 LSTM이 일중 주기성 등 복잡한 패턴을 성공적으로 학습했음을 시사한다.

Transformer: 모든 지표에서 최고의 성능을 보였다. RMSE 3.24, MAE 2.24로 평균적인 예측 오차 규모가 가장 작다. MAPE 14.21%는 예측값이 실제값과 매우 유사한 수준임을 뜻하며, R² 0.91는 모형이 매우 높은 설명력을 가짐을 나타낸다. 이는 Transformer가 시계열 데이터의 장기 의존성과 복잡한 패턴을 성공적으로 학습했음을 시사한다.

![상세 예측 결과 비교(확대)](https://github.com/comsa33/time-series-auto-llm-paper-ma/blob/1148baa89a09ae8e7d77a124831a93c50cbe835c/research_results/analysis_plots/model_forecast_comparision_plot_pm25_zoomin.png)

그림 4.3: 예측 결과 확대 비교 (테스트 기간 중 일부)

위의 결과를 종합하면, **딥러닝 기반 모델(Transformer, LSTM)**이 **통계적 모델(지수평활법, ARIMA, Prophet)**보다 월등히 뛰어난 예측 성능을 발휘했다. 특히 Transformer는 오차율 15% 미만으로, 실제 활용에도 무리가 없을 정도의 정확도를 달성하였다. 반면 지수평활법이나 Prophet은 시계열 decomposed 구조를 가정하고 있음에도 불구하고, 너무 짧고 변동이 심한 데이터 특성에 적응하지 못해 사실상 예측에 실패하였다. ARIMA는 어느 정도 기본적인 패턴은 맞추었으나, 정확도 면에서는 만족스럽지 않은 수준이다.
