제 2 절 하이퍼파라미터 튜닝과 AutoML
머신러닝 모델의 성능은 모델 구조뿐만 아니라 학습률, 정규화 계수, 트리의 개수 등 다양한 하이퍼파라미터(hyperparameter) 설정에 크게 좌우된다. 하이퍼파라미터는 학습 과정에서 자동으로 학습되지 않으며 사전에 사람이 지정해야 하는 값으로, 최적의 조합을 찾기 위해서는 많은 시행착오가 필요하다. 그리드 탐색(grid search)이나 전문가의 수동 조정과 같은 전통적인 방법은 높은 연산 비용에도 불구하고 널리 사용되어 왔으나, 탐색 공간이 클 경우 비효율적이라는 한계가 있다. 무작위 탐색(random search) 방식은 격자 탐색 대비 동일한 자원 내에서 더 다양한 조합을 시도함으로써 효율을 높일 수 있음을 이론적·경험적으로 보인 바 있다 (Bergstra & Bengio, 2012). 이러한 하이퍼파라미터 최적화에 대한 관심으로, 베이지안 최적화나 진화 알고리즘 등 자동화된 탐색 기법들이 연구되어 왔으며, 이를 통해 최소한의 시도만으로도 양호한 성능을 달성할 수 있는 파라미터 조합을 발견하는 접근법들이 제안되었다.
하이퍼파라미터 튜닝의 발전은 단일 모델 수준을 넘어 자동화된 머신러닝(AutoML)의 개념으로 확장되었다. AutoML은 비전문가도 머신러닝을 효과적으로 활용할 수 있도록, 알고리즘 선택부터 특징 공학(feature engineering), 하이퍼파라미터 최적화, 그리고 모델 평가에 이르는 전 과정을 자동화하는 것을 목표로 한다. 예를 들어 Feurer et al. (2015)는 auto-sklearn이라는 시스템을 선보였는데, 이는 사전 정의된 여러 학습 알고리즘과 전처리 기법들 가운데 최적의 조합을 베이지안 최적화를 통해 탐색하고, 과거 유사 데이터셋에서의 성능 정보를 활용한 메타러닝(meta-learning)으로 탐색 효율을 높이며, 최종적으로 앙상블 기법으로 다수의 우수 모델을 조합함으로써 안정적인 예측 성능을 얻는 AutoML 구현체이다. 이처럼 AutoML 기법은 모델 선택과 하이퍼파라미터 튜닝에 필요한 막대한 시간을 절감할 수 있고, 전문가의 개입을 최소화함으로써 머신러닝 모델 개발을 대중화하는 데 기여하고 있다. 다만 완전한 자동화에도 한계는 존재하는바, AutoML 시스템 자체의 설정(예: 탐색 예산, 평가 지표) 역시 성능에 영향을 주는 또 다른 계층의 하이퍼파라미터로 남아있다. 그럼에도 불구하고 최근 AutoML은 분류나 회귀뿐 아니라 시계열 예측 등 다양한 문제 영역에 적용되며 그 효용을 입증하고 있어, 시계열 모델 구축에도 AutoML을 도입하는 시도가 증가하고 있다.
