제 3 절 생성형 AI와 시계열 분석
생성형 AI는 주어진 훈련 데이터 분포로부터 새로운 데이터를 생성해내는 인공지능 기술로, 이미지 생성 모델(DALL-E 등)부터 텍스트 생성 모델(GPT 계열)까지 폭넓은 분야에 걸쳐 발전해왔다. 그 중에서도 방대한 매개변수를 갖춘 대규모 언어 모델은 대용량의 텍스트 코퍼스를 학습하여 인간 수준의 언어 이해와 생성 능력을 보여주는 대표적인 생성형 AI이다. GPT-4 기술 보고서에 따르면, GPT-4 모델은 이전 세대 대비 한층 향상된 추론 능력과 광범위한 지식 축적을 바탕으로 복잡한 문제도 높은 정확도로 해결해낸다 (OpenAI, 2023). 이러한 LLM의 부상은 자연어 처리 외의 영역에서도 새로운 접근 방식을 제시하고 있다. 시계열 데이터의 분석 역시 그 한 예로, 전통적으로는 통계적 방법론이나 딥러닝 전용 아키텍처(e.g., LSTM, Transformer 계열 모델)에 의존하던 영역에 LLM과 같은 범용 인공지능을 활용하려는 움직임이 나타나고 있다. 현재까지 시계열 분석에 특화된 일반 인공지능은 부재한 상태이지만, 최근 연구자들은 LLM이 이 격차를 메우는 열쇠가 될 수 있다고 전망한다 (Jin et al., 2024). Jin et al. (2024)은 시계열 분석을 위한 인공지능의 보편화 가능성을 논하며, 기존 시계열 모델들이 예측(task)에 국한되고 도메인 지식 및 세심한 튜닝을 필요로 하는 반면, 최신 LLM은 풍부한 사전학습을 통해 시계열 데이터 자체에 내재된 패턴을 인지하고 추론하는 능력을 잠재적으로 갖추고 있다고 주장한다. 예를 들어 LLM을 활용하면 시계열 질의응답(Q&A)이나 모달리티 전환(time series modality switching)과 같은 새로운 형태의 분석도 가능해질 수 있으며, 기존에 별개로 다뤄지던 텍스트 정보와 시계열 신호를 통합적으로 해석하는 등 범용적인 시계열 분석 지능으로의 발전을 기대해볼 수 있다는 것이다. 다만 저자들은 이러한 잠재력을 실현하기 위해서는 모델의 예측에 대한 신뢰성 확보와 같은 추가 연구 과제가 수반됨을 강조하고 있다. 요컨대, 생성형 AI—특히 LLM의 등장—는 시계열 데이터 처리 영역에서 패러다임 전환의 기회를 제공하지만, 이를 뒷받침할 이론적·경험적 검증이 아직은 초기 단계에 있다는 것이 학계의 인식이다.
구체적인 사례로서, 대규모 언어 모델을 시계열 예측에 활용하려는 최신 시도들은 그 가능성과 한계를 함께 보여준다. Gruver et al. (2023)은 사전학습된 LLM에 추가 학습 없이(zero-shot) 시계열 예측을 수행하는 창의적인 접근을 제안하였다. 이들은 연속적인 시계열 수치를 문자 기반 문자열로 인코딩하여 다음 토큰 예측 문제로 변환함으로써, GPT-3나 LLaMA-2와 같은 언어 모델에 시계열의 연장선상을 그대로 예측하게 하는 방법을 시도하였다. 흥미롭게도, 별도 모델 학습 없이도 LLM이 생성한 예측치는 기존에 특화 설계된 시계열 모델의 성능에 필적하거나 그 이상인 것으로 나타났다 (Gruver et al., 2023). 이는 인간 언어의 확률 분포를 학습한 LLM이 시계열 데이터의 패턴과 확률 분포도 일정 수준 학습하고 있음을 시사한다. 특히 대규모 언어 모델은 복잡한 다중모달 분포(multi-modal distribution)를 표현하는 능력이 뛰어나며, 결과 시퀀스에서 관찰되는 규칙성과 반복성(예: 계절적 주기 패턴)을 효율적으로 포착하는 경향이 있어 시계열 예측에 유리하게 작용한 것으로 분석된다. 또한 텍스트 형식으로 접근하기 때문에 결측치 처리를 위한 특수 토큰을 삽입하거나 텍스트 메타정보(날씨 설명 등 부가 정보)를 함께 제공하여 부가적 요인 통합이 자연스럽게 이루어지는 장점도 보고되었다 (Gruver et al., 2023). 더 나아가 이러한 접근은 예측 결과에 대한 설명 생성도 가능하게 하는데, 예컨대 모델이 산출한 미래 예측에 대해 원인이나 추이를 자연어로 설명하도록 프롬프트를 구성할 수도 있다. 한편, 모든 LLM이 균일한 성능을 보이는 것은 아니다. Gruver 등의 연구에 따르면 GPT-4와 같은 최신 모델이 반드시 GPT-3보다 나은 결과를 내지 못하는 경우도 있었는데, 이는 수치 정보에 대한 토큰화 방식의 차이나 인간 피드백 강화학습(RLHF)에 따른 모델 보정의 부작용으로 인해 예측 분포가 왜곡될 가능성을 시사한다. 이러한 한계에도 불구하고, 대규모 언어 모델의 시계열 활용은 추가 튜닝이나 복잡한 아키텍처 설계 없이도 강건한 예측 능력을 보여줄 수 있음을 증명함으로써 새로운 연구 방향을 열었다. 결국 생성형 AI를 시계열 분석에 접목하려는 흐름은 AutoML과 더불어 인공지능의 자동화된 지능화라는 큰 흐름 속에서, 향후 시계열 예측의 효율성과 효과성을 크게 높일 수 있는 잠재력을 지닌다는 점에서 의미가 크다고 하겠다.
