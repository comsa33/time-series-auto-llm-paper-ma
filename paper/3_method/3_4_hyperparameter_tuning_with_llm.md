3.4 LLM 기반 하이퍼파라미터 튜닝 절차

본 연구의 핵심 차별점은 **대규모 언어 모델(LLM)[6,7]**을 활용하여 위의 예측 모델들의 하이퍼파라미터를 자동으로 튜닝한 점이다. 이를 위해 반복적 상호작용(iterative interaction) 방식을 설계하였다. 절 3.1에서 소개한 바와 같이, 초기 모델들을 훈련한 후 **LLM에게 질의(prompt)**를 보내는데, 이 프롬프트에는 각 모델의 현재 성능 지표와 특징이 요약되어 있다. 예를 들면 다음과 같은 형태이다:

    모델별 현재 성능: 
    - Exponential Smoothing: RMSE=251.16, MAPE=1619.78 (오차 매우 큼)  
    - ARIMA: RMSE=13.41, MAPE=100.22  
    - Prophet: RMSE=31.86, MAPE=223.82  
    - LSTM: RMSE=4.29, MAPE=19.63  
    - Transformer: RMSE=5.47, MAPE=26.33  

    데이터는 하루(24시간) 주기의 계절성을 보임. 
    각 모델의 성능을 향상시킬 수 있는 하이퍼파라미터 조정이나 방법을 제안하라.

LLM(Gemma3:27B)[6,7]는 이 정보를 바탕으로 각 모델별로 개선할 만한 부분을 텍스트 형태로 답변한다. 예를 들어 실제 상호작용에서 LLM은 다음과 같은 유의미한 제안을 내놓았다:

Exponential Smoothing에 대해: “데이터에 뚜렷한 일중 주기성이 있으므로, 계절 구성요소를 포함한 삼중 지수평활법을 사용해야 합니다. 또한 현재 MAPE가 매우 높으므로 계절 패턴이 잘 맞지 않은 것으로 보입니다. 계절성 구성의 모델을 Multiplicative로 바꿔보는 것도 고려하세요.”

(조치: 이미 계절성은 Additive로 포함했으므로, LLM의 제안 중 Multiplicative 시즌을 테스트했으나 성능 개선이 없어 유지하지 않음.)


ARIMA에 대해: “ARIMA 모델의 MAPE가 100% 수준으로 좋지 않습니다. 하루 주기의 계절성을 반영하기 위해 계절 ARIMA를 사용해보십시오. (P,D,Q,m)에서 m=24로 설정하고, p와 q는 현재 1로 보이는데 약간 증가시켜 볼 수 있습니다. 또한 데이터가 정적이지 않다면 1차 차분(d=1)을 적용해보세요.”

(조치: SARIMA(1,1,1)x(1,0,1,24)를 시도했으나 데이터 기간이 짧아 오히려 과적합되어 제외. 대신 non-seasonal ARIMA(1,0,1)을 유지.)


Prophet에 대해: “Prophet 모델의 오차가 큰 것은 데이터 기간이 짧고 변동이 심하기 때문입니다. 변화점 감도를 높여서 추세 변화를 더 많이 포착하거나, 외부 영향(예: 기상 정보)을 추가 특징으로 넣는 방법을 고려하세요.”

(조치: changepoint_prior_scale를 이미 0.1로 높였으나 추가로 0.2까지 높여봤으나 큰 차이 없어 0.1 유지. 외부 요인은 본 연구 범위 밖이라 미적용.)

LSTM에 대해: “LSTM이 가장 성능이 좋지만 더 개선하려면, 현재 은닉노드 수를 늘리거나 층을 하나 더 깊게 쌓는 것을 고려하세요. 하지만 과적합 위험이 있으므로 검증 오차를 모니터링하세요. 또한 시퀀스 길이를 24보다 더 늘려 이틀 정도(48)로 해보는 것도 좋습니다.”

(조치: 은닉노드를 50→100으로 증가 (성능 개선 확인), 층을 2개로 늘렸더니 오히려 데이터 부족으로 과적합되어 다시 1개로 환원. 시퀀스 길이 48로도 시도했으나 24와 큰 차이 없어서 24 유지.)

Transformer에 대해: “Transformer의 경우 LSTM보다 성능이 약간 떨어지는데, 데이터가 많지 않아 복잡한 모델이 충분히 학습되지 못한 탓일 수 있습니다. 모델 규모를 줄이거나 정규화를 추가하세요. 예를 들어 인코더 층수를 2→1로 줄이거나, 학습률을 낮춰 천천히 학습시키는 방법을 제안합니다.”

 (조치: 인코더 층 1로 줄인 모델을 시험했으나 표현력이 약해져 성능 하락, 다시 2층 유지. 대신 EarlyStopping을 적용하고 학습 epoch를 증가시켜 안정적으로 학습하도록 함.)

이러한 LLM의 제안은 기존 도메인 지식과 비슷한 맥락도 있고 새로운 시도도 있었다. 연구자는 LLM의 제안을 그때그때 수용하여 모델에 반영하고, 개선되었는지 여부를 테스트하였다. 이 과정을 필요에 따라 여러 차례 반복함으로써, 마치 사람 전문가와 상의하듯이 모델을 조율해 나갔다. 중요한 점은 LLM의 조언이 항상 이득이 되는 것은 아니므로, 각 변경 후에는 반드시 검증 데이터에 대한 성능을 측정하여 유지하거나 롤백하였다.

LLM 기반 튜닝의 결과, 특히 LSTM 모델의 성능이 크게 향상되었다. 초기 설정(은닉노드 50 등)에서 RMSE 약 5 이상이었는데, 튜닝 후 RMSE를 4.3 수준으로 낮출 수 있었다. Transformer도 정규화와 학습 전략 개선으로 RMSE가 약간 감소하는 효과를 보였다. 반면 ARIMA나 Prophet 등은 LLM이 제안한 대로 시도해보았지만 데이터 특성상 본질적인 한계가 있어 성능 향상이 미미하였다. 그럼에도 불구하고, LLM의 개입으로 다양한 조합을 빠르게 탐색해볼 수 있었고, 그 과정에서 몇몇 비교 실험이 자동으로 이루어졌다는 점에서 시간과 노력을 절감할 수 있었다.

정리하면, 하이퍼파라미터 자동 튜닝 절차는 다음과 같은 사이클로 수행되었다:
1. 초기 모델 학습 및 평가 (성능 지표 계산).
2. 현재 결과를 요약하여 LLM에 질의.
3. LLM의 하이퍼파라미터 조정 제안 수신.
4. 각 제안을 해당 모델에 적용하여 재학습 및 검증.
5. 성능이 개선되면 변경 유지, 악화되면 철회.
6. 필요시 2~5단계를 반복.

이 과정을 통해 최종적으로 모든 모델의 성능이 초기보다 개선되었으며(특히 LSTM과 Transformer), 가장 성능이 좋은 모델을 선정할 수 있었다. LLM이 제시한 논거들은 보고서 작성 시에도 활용되어, 결과를 설명하는 근거로 사용되었다.

| 지표    | LSTM | 튜닝된 LSTM | 향상률(%) |
|---------|------|------------|-----------|
| MSE     | 22.09| 7.63      | 65.46%    |
| RMSE    | 4.70 | 2.76      | 41.23%    |
